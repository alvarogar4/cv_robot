{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.covariance import ShrunkCovariance\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "\n",
    "class ClassifEuclid(Classifier):\n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor de la clase\"\"\"\n",
    "        self.centroids = None\n",
    "        \n",
    "    def fit(self,X, y):\n",
    "        \"\"\"Entrena el clasificador\n",
    "        X: matriz numpy, cada fila es un dato, cada columna una medida del vector de caracteristicas.\n",
    "        y: vector de etiquetas de clase, tantos elementos como filas en X.\n",
    "        Retorna objeto clasificador\"\"\"\n",
    "\n",
    "        assert X.ndim == 2 and X.shape[0] == len(y)\n",
    "        \n",
    "        # Find the centroids\n",
    "        self.centroids = np.array([np.mean(X[y == t], axis = 0) for t in np.unique(y)])\n",
    "\n",
    "        #print(f\"centroids: {self.centroids}\")\n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"Estima el grado de pertenencia de todos los datos a todas las clases \n",
    "        X: matriz numpy, cada fila es un dato, cada columna una medida del vector de caracteristicas. \n",
    "        Retorna una matriz, con tantas filas como datos y tantas columnas como clases tenga\n",
    "        el problema, cada fila almacena los valores pertenencia de un dato a cada clase\"\"\" \n",
    "        assert self.centroids is not None, \"Error: The classifier needs to be fitted. Please call fit(X, y) method.\"\n",
    "        assert X.ndim == 2 and X.shape[1] == self.centroids.shape[1]        \n",
    "        \n",
    "        # Distance: 150,1,4 - 1,3,4 -> 150,3,4 -> 150,3\n",
    "        res = np.linalg.norm(X[:, np.newaxis, :] - self.centroids[np.newaxis, :, :], axis = 2)\n",
    "        \n",
    "        #print(f\"distances: {res}\")\n",
    "        return res\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predice una clase para cada dato. La clase retornada debe ser un entero.\n",
    "        X: matriz numpy donde cada fila es un dato, cada columna una medida.\n",
    "        Retorna un vector con la clase predicha para cada dato\"\"\"\n",
    "        \n",
    "        # Find the distances to the centroids\n",
    "        distances = self.decision_function(X)\n",
    "\n",
    "        # Find the shortest distance\n",
    "        res = np.argmin(distances, axis = 1)\n",
    "        \n",
    "        #print(f\"Predicted: {res}\")\n",
    "        return res\n",
    "\n",
    "    \n",
    "def test(X, Y):\n",
    "    return np.sum(X != Y) # Number of different values between X and Y\n",
    "\n",
    "\n",
    "color_red = np.array([255, 0, 0])\n",
    "color_green = np.array([0, 255, 0])\n",
    "color_blue = np.array([0, 0, 255])\n",
    "paleta = np.array([[0, 0, 255], [255, 255, 255], [255, 0, 0]])\n",
    "\n",
    "im_border = np.zeros((150, 320), dtype = np.bool)\n",
    "\n",
    "for i in range(150):\n",
    "    for j in range(320):\n",
    "        if i<3 or i>147 or j<3 or j>317:\n",
    "            im_border[i,j] = True\n",
    "        else:\n",
    "            im_border[i,j] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ClassifEuclid at 0x7feae4923f10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imageio import imread, imsave\n",
    "\n",
    "# Cargamos los datos para entrenar\n",
    "marked = imread(\"imgs/train/marked.png\")\n",
    "norm = imread(\"imgs/train/norm.png\")\n",
    "\n",
    "red_mask = np.sum(marked==color_red, axis=2) == 3\n",
    "green_mask = np.sum(marked==color_green, axis=2) == 3\n",
    "blue_mask = np.sum(marked==color_blue, axis=2) == 3\n",
    "\n",
    "\n",
    "# Datos de refuerzo para la marca cuando le da la luz\n",
    "marked_2 = imread(\"imgs/train/marked_2.png\")\n",
    "norm_2 = imread(\"imgs/train/norm_2.png\")\n",
    "\n",
    "red_mask_2 = np.sum(marked_2==color_red, axis=2) == 3\n",
    "\n",
    "X_marca = norm[red_mask]\n",
    "X_marca_2 = norm_2[red_mask_2]\n",
    "X_fondo = norm[green_mask]\n",
    "X_linea = norm[blue_mask]\n",
    "\n",
    "n_marca,_ = X_marca.shape\n",
    "n_marca_2,_ = X_marca_2.shape\n",
    "n_fondo,_ = X_fondo.shape\n",
    "n_linea,_ = X_linea.shape\n",
    "\n",
    "y_marca = np.zeros((n_marca),dtype=int)\n",
    "y_marca_2 = np.zeros((n_marca_2),dtype=int)\n",
    "y_fondo = np.ones((n_fondo),dtype=int)\n",
    "y_linea = np.ones((n_linea),dtype=int) + 1\n",
    "\n",
    "# Entrenamiento normal\n",
    "X = np.concatenate((X_marca_2, X_fondo, X_linea), axis=0)\n",
    "y = np.concatenate((y_marca_2, y_fondo, y_linea), axis=0)\n",
    "\n",
    "# Pruebas\n",
    "#X = np.concatenate((X_marca, X_marca_2, X_fondo, X_linea), axis=0)\n",
    "#y = np.concatenate((y_marca, y_marca_2, y_fondo, y_linea), axis=0)\n",
    "\n",
    "# Elegir el clasificador\n",
    "classifier = ClassifEuclid()\n",
    "\n",
    "# Entrenar el clasificador\n",
    "classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 781,
     "status": "error",
     "timestamp": 1618161906815,
     "user": {
      "displayName": "Alvaro gg",
      "photoUrl": "",
      "userId": "06655085499050793757"
     },
     "user_tz": -120
    },
    "id": "dE-1ju6m42wY",
    "outputId": "995f55ad-d6cf-4225-81d2-63f58c80f309"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from operator import itemgetter\n",
    "import math\n",
    "\n",
    "def rg_norm_img(img):\n",
    "    return img / np.sum(img, axis=2)[:, :, np.newaxis] * 255\n",
    "\n",
    "\n",
    "def segment(img):\n",
    "    \n",
    "    img_h,img_w,_ = img.shape\n",
    "    \n",
    "    img_norm = rg_norm_img(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    img_aux = np.reshape(img_norm, (-1, 3))   \n",
    "    predicted = classifier.predict(img_aux)\n",
    "    img_res_paleta = paleta[np.reshape(predicted,(img_h,img_w))]\n",
    "    img_res = np.reshape(predicted,(img_h,img_w))\n",
    "    \n",
    "    return img_res,img_res_paleta\n",
    "\n",
    "\n",
    "def define_case(im, img_seg):\n",
    "\n",
    "    # Separo los bordes a partir de las etiquetas de segmentaci칩n y extraigo los contornos\n",
    "    img_grey_line = (img_seg==2).astype(\"uint8\")*255\n",
    "    border = np.logical_and(img_grey_line, im_border).astype(\"uint8\")*255\n",
    "    contList,hier = cv2.findContours(border,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Pinto los contornos\n",
    "    #img_cont = cv2.drawContours(np.float32(im), contList, -1, (0,255,0))\n",
    "    img_cont = cv2.drawContours(np.float32(im), [], -1, (0,255,0))\n",
    "    \n",
    "    # Calculolos centros de los contornos\n",
    "    cent = []\n",
    "    for c in contList:\n",
    "        M = cv2.moments(c)\n",
    "        try:\n",
    "            center = [M[\"m10\"]/M[\"m00\"], M[\"m01\"] / M[\"m00\"]]\n",
    "        except:\n",
    "            center = [M[\"m10\"]/1, M[\"m01\"]/1]\n",
    "        cent.append(center)\n",
    "        \n",
    "    # Pintamos las salidas y la entrada\n",
    "    for c in cent:\n",
    "        img_cont = cv2.circle(img_cont, (int(c[0]),int(c[1])), 8, (0,32,255), 15)\n",
    "    \n",
    "    # Defino el caso en funcion del numero de contornos\n",
    "    n = len(contList)\n",
    "    case = -1\n",
    "    \n",
    "    if n < 3:\n",
    "        d = [cent[0][0]-cent[1][0], cent[0][1]-cent[1][1]]\n",
    "        \n",
    "        if d[0] < -50:\n",
    "            text = cv2.putText(img_cont, 'Curva a la derecha', org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            case = 1 \n",
    "        elif d[0] > 50:\n",
    "            text = cv2.putText(img_cont, 'Curva a la izquerda', org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            case = 0 \n",
    "        else:\n",
    "            text = cv2.putText(img_cont, 'Linea recta', org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            case = 0\n",
    "\n",
    "    elif n < 4:\n",
    "        text = cv2.putText(img_cont, 'Bifurcacion en Y', org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        case = 3\n",
    "        \n",
    "    elif n < 5:\n",
    "        text = cv2.putText(img_cont, 'Cruce en X', org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        case = 4\n",
    "        \n",
    "    return img_cont, case, cent\n",
    "\n",
    "\n",
    "def study_arrow(im, img_seg, case, arrow, acc):\n",
    "    \n",
    "    d = \"None\"\n",
    "    \n",
    "    # Construyo im치genes a partir de las etiquetas de segmentaci칩n y extraigo los contornos\n",
    "    img_grey_mark = (img_seg==0).astype(\"uint8\")*255 \n",
    "    contList,hier = cv2.findContours(img_grey_mark,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Cojo el contorno mas grande con un 치rea mayor a 200\n",
    "    if len(contList) != 0:\n",
    "        contList = [max(contList, key = cv2.contourArea)]\n",
    "        area = cv2.contourArea(contList[0])\n",
    "        \n",
    "        if area < 200:\n",
    "            contList = []\n",
    "    \n",
    "    # Pinto los contornos\n",
    "    #img_cont = cv2.drawContours(np.float32(im), contList, -1, (0,255,0))\n",
    "    \n",
    "    # Evaluamos la flecha si la hay\n",
    "    if len(contList) > 0:\n",
    "        # Calculo el centro de gravedad\n",
    "        M = cv2.moments(contList[0])\n",
    "        try:\n",
    "            gravity_center = [M[\"m10\"]/M[\"m00\"], M[\"m01\"] / M[\"m00\"]]\n",
    "        except:\n",
    "            gravity_center = [M[\"m10\"]/1, M[\"m01\"]/1]\n",
    "        \n",
    "        #img_cont = cv2.circle(img_cont, (int(gravity_center[0]),int(gravity_center[1])), 2, (0,32,255), 2)\n",
    "                \n",
    "        # Calculo el centro del rectangulo que contiene la flecha\n",
    "        rect = cv2.minAreaRect(contList[0])\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        #im = cv2.drawContours(im,[box],0,(0,32,255),2)\n",
    "        \n",
    "        M = cv2.moments(box)\n",
    "        try:\n",
    "            center = [M[\"m10\"]/M[\"m00\"], M[\"m01\"] / M[\"m00\"]]\n",
    "        except:\n",
    "            center = [M[\"m10\"]/1, M[\"m01\"]/1]\n",
    "        \n",
    "        #img_cont = cv2.circle(img_cont, (int(center[0]),int(center[1])), 2, (0,255,255), 2)\n",
    "        \n",
    "        # Calculo la direccion en funcion de los centros calculados\n",
    "        v_dir = [center[0]-gravity_center[0], center[1]-gravity_center[1]]\n",
    "        \n",
    "        if abs(v_dir[0]) > abs(v_dir[1]):\n",
    "            if v_dir[0] > 0:\n",
    "                acc[0] = acc[0] + 1\n",
    "            else:\n",
    "                acc[1] = acc[1] + 1\n",
    "        else:\n",
    "            if v_dir[1] >= 0:\n",
    "                acc[2] = acc[2] + 1\n",
    "            else:\n",
    "                acc[3] = acc[3] + 1\n",
    "        \n",
    "        # Establezco la direccion de la flecha\n",
    "        if acc[0] > acc[1] and acc[0] > acc[2] and acc[0] >= acc[3]:\n",
    "            d = \"izquierda\"\n",
    "            arrow = 0\n",
    "        elif acc[1] >= acc[0] and acc[1] > acc[2] and acc[1] >= acc[3]:\n",
    "            d = \"derecha\"\n",
    "            arrow = 1\n",
    "        elif acc[2] >= acc[0] and acc[2] >= acc[1] and acc[2] >= acc[3]:\n",
    "            d = \"frente\"\n",
    "            arrow = 2\n",
    "        elif acc[3] > acc[0] and acc[3] > acc[1] and acc[3] > acc[2]:\n",
    "            d = \"atras\"\n",
    "            arrow = 3\n",
    "\n",
    "    return img_cont, d, arrow, acc        \n",
    "    \n",
    "\n",
    "def study_marks(img_cont, img_seg, im_seg_paleta, acc):\n",
    "    \n",
    "    # Construyo im치genes a partir de las etiquetas de segmentaci칩n y extraigo los contornos\n",
    "    img_grey_mark = (img_seg==0).astype(\"uint8\")*255 \n",
    "    contList,hier = cv2.findContours(img_grey_mark,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Cojo el contorno mas grande\n",
    "    if len(contList) != 0:\n",
    "        contList = [max(contList, key = cv2.contourArea)]\n",
    "        area = cv2.contourArea(contList[0])\n",
    "        \n",
    "        if area < 50:\n",
    "            contList = []\n",
    "            \n",
    "    #img_cont = cv2.drawContours(np.float32(img_cont), contList, -1, (0,255,0))\n",
    "    \n",
    "    if len(contList) != 0:\n",
    "        des =  orb_descriptors(contList[0], img_grey_mark)\n",
    "\n",
    "        if des is not None:\n",
    "            mark = neigh.predict([des])\n",
    "            acc[int(mark)] = acc[int(mark)] + 1\n",
    "            \n",
    "            # Establezco la direccion de la flecha\n",
    "            if acc[0] > acc[1] and acc[0] > acc[2] and acc[0] >= acc[3]:\n",
    "                mark_text = \"Hombre\"\n",
    "            elif acc[1] >= acc[0] and acc[1] > acc[2] and acc[1] >= acc[3]:\n",
    "                mark_text = \"Escalera\"\n",
    "            elif acc[2] >= acc[0] and acc[2] >= acc[1] and acc[2] >= acc[3]:\n",
    "                mark_text = \"Telefono\"\n",
    "            elif acc[3] > acc[0] and acc[3] > acc[1] and acc[3] > acc[2]:\n",
    "                mark_text = \"Mujer\"\n",
    "            \n",
    "            text = cv2.putText(img_cont, f'marca: {mark_text}', org_5, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            \n",
    "        else:\n",
    "            acc = [0,0,0,0]\n",
    "            \n",
    "    return img_cont, acc\n",
    "\n",
    "\n",
    "def orb_descriptors(cont, im):\n",
    "    \n",
    "    orb = cv2.ORB_create()\n",
    "    ellip = cv2.fitEllipse(cont)\n",
    "    cen, ejes, angulo = np.array(ellip[0]), np.array(ellip[1]), ellip[2]\n",
    "    if angulo > 90:\n",
    "        angulo -= 180\n",
    "        \n",
    "    kp = cv2.KeyPoint(cen[0], cen[1], np.mean(ejes)*1.3, angulo - 90)\n",
    "    lkp, des = orb.compute(im, [kp])\n",
    "    \n",
    "    if des is not None:\n",
    "        return np.unpackbits(des).T\n",
    "    return None\n",
    "\n",
    "\n",
    "def eval_exit(img_cont, cent, arrow):\n",
    "\n",
    "    if arrow == 0:\n",
    "        exit = min(cent, key=itemgetter(0))\n",
    "    elif arrow == 1:\n",
    "        exit = max(cent, key=itemgetter(0))\n",
    "    elif arrow == 2:\n",
    "        exit = min(cent, key=itemgetter(1))\n",
    "    elif arrow == 3:\n",
    "        exit = max(cent, key=itemgetter(1))\n",
    "    \n",
    "    img_cont = cv2.circle(img_cont, (int(exit[0]),int(exit[1])), 8, (255,0,255), 15)\n",
    "    \n",
    "    if exit[1] < 60:\n",
    "        eX = 60\n",
    "    else:\n",
    "        eX = exit[1]\n",
    "\n",
    "    vel = round((151 - exit[1]) / 150, 2)\n",
    "    ang = round(((exit[0] - 160) * eX) / (320 * 75), 2)\n",
    "    \n",
    "    cv2.putText(img_cont, f\"velocidad: {vel}\", org_3, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    cv2.putText(img_cont, f\"angulo: {ang}\", org_4, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        \n",
    "    return img_cont\n",
    "\n",
    "\n",
    "def vid_classifier(vid):\n",
    "    \n",
    "    capture = cv2.VideoCapture(vid)\n",
    "    ret,im = capture.read()\n",
    "\n",
    "    img_h,img_w,_=im.shape\n",
    "    out = cv2.VideoWriter('videos/output/clasificado_2.avi', cv2.VideoWriter_fourcc(*'XVID'), 20.0, (img_w,img_h))\n",
    "    \n",
    "    while(ret):\n",
    "        # Nuevo video\n",
    "        img_seg = segment(im)\n",
    "        out.write(img_seg.astype('uint8'))\n",
    "        \n",
    "        ret,im = capture.read()\n",
    " \n",
    "    capture.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El clasificador ha cometido un total de 2 errores al analizar 57756 elementos, por lo tanto tiene un 99.9965% de acierto\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos para probar\n",
    "marked = imread(\"imgs/train/test_marked.png\")\n",
    "norm = imread(\"imgs/train/test_norm.png\")\n",
    "\n",
    "red_mask = np.sum(marked==color_red, axis=2) == 3\n",
    "green_mask = np.sum(marked==color_green, axis=2) == 3\n",
    "blue_mask = np.sum(marked==color_blue, axis=2) == 3\n",
    "\n",
    "X_marca = norm[red_mask]\n",
    "X_fondo = norm[green_mask]\n",
    "X_linea = norm[blue_mask]\n",
    "\n",
    "n_marca,_ = X_marca.shape\n",
    "n_marca_2,_ = X_marca_2.shape\n",
    "n_fondo,_ = X_fondo.shape\n",
    "n_linea,_ = X_linea.shape\n",
    "\n",
    "y_marca = np.zeros((n_marca),dtype=int)\n",
    "y_fondo = np.ones((n_fondo),dtype=int)\n",
    "y_linea = np.ones((n_linea),dtype=int) + 1\n",
    "\n",
    "# Entrenamiento normal\n",
    "X = np.concatenate((X_marca_2, X_fondo, X_linea), axis=0)\n",
    "y_res = np.concatenate((y_marca_2, y_fondo, y_linea), axis=0)\n",
    "\n",
    "y = classifier.predict(X)\n",
    "\n",
    "errors = test(y, y_res)\n",
    "total = len(y)\n",
    "\n",
    "print(f\"El clasificador ha cometido un total de {errors} errores al analizar {total} elementos, por lo tanto tiene un {round((((total-errors)/total)*100),4)}% de acierto\")\n",
    "\n",
    "#_,img_res_paleta = segment(norm)\n",
    "#plt.imshow(img_res_paleta)\n",
    "#plt.show()\n",
    "#imsave(f'imgs/train/test_res.png',img_res_paleta.astype('uint8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-084e151e2883>:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return img / np.sum(img, axis=2)[:, :, np.newaxis] * 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El clasificador ha cometido un total de 1 errores al analizar 6 elementos, por lo tanto tiene un 83.3333% de acierto\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "X = np.empty((28,256))\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0 ,1 ,1 ,1 ,1 ,1 ,1 ,1, 2 ,2 ,2 ,2 ,2 ,2 ,2 ,3 ,3 ,3 ,3 ,3 ,3 ,3])\n",
    "\n",
    "for i in range(1,29):\n",
    "    \n",
    "    im = imread(f\"imgs/marcas/{i}.png\")\n",
    "        \n",
    "    img_seg, img_seg_paleta = segment(im)\n",
    "    \n",
    "    img_grey_mark = (img_seg==2).astype(\"uint8\")*255\n",
    "    \n",
    "    contList,hier = cv2.findContours(img_grey_mark,cv2.RETR_LIST,cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Cojo el contorno mas grande\n",
    "    if len(contList) != 0:\n",
    "        contList = [max(contList, key = cv2.contourArea)]\n",
    "        area = cv2.contourArea(contList[0])\n",
    "        \n",
    "        if area < 50:\n",
    "            contList = []\n",
    "    \n",
    "    img_cont = cv2.drawContours(np.float32(img_grey_mark), contList, -1, (255,0,255))\n",
    "    \n",
    "    X[i-1] = orb_descriptors(contList[0], img_grey_mark)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)      \n",
    "    \n",
    "neigh = KNeighborsClassifier(1, metric=\"euclidean\")\n",
    "neigh.fit(X_train, y_train)\n",
    "joblib.dump(neigh, './clf/clf.pkl')\n",
    "\n",
    "y_res = neigh.predict(X_test)\n",
    "errors = test(y_test, y_res)\n",
    "total = len(y_test)\n",
    "\n",
    "print(f\"El clasificador ha cometido un total de {errors} errores al analizar {total} elementos, por lo tanto tiene un {round((((total-errors)/total)*100),4)}% de acierto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kqv_1IYg42wa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from imageio import imread, imsave\n",
    "    \n",
    "# Text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "org = (15, 15)\n",
    "org_2 = (15,30)\n",
    "org_3 = (15,45)\n",
    "org_4 = (15,60)\n",
    "org_5 = (15,75)\n",
    "fontScale = 0.5\n",
    "color = (0, 0, 0)\n",
    "thickness = 1\n",
    "\n",
    "#Captura de imagenes \n",
    "capture = cv2.VideoCapture('videos/video-2.avi')\n",
    "out = cv2.VideoWriter('videos/output/clasificado_2.avi', cv2.VideoWriter_fourcc(*'XVID'), 20.0, (320, 150))\n",
    "\n",
    "# Parametros auxiliares\n",
    "key = \"\"\n",
    "arrow = 2\n",
    "acc = [0,0,0,0]\n",
    "acc_mark = [0,0,0,0]\n",
    "\n",
    "while (key != ord('q')):\n",
    "    \n",
    "    # Leo una imagen del video\n",
    "    ret,im = capture.read()\n",
    "    \n",
    "    # Si no hay m치s imagenes paramos\n",
    "    if not ret:\n",
    "        print('Se acabo el video.')\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    # Recorto la imagen\n",
    "    im = im[90:,:]\n",
    "    \n",
    "    # Segmento la imagen\n",
    "    img_seg, img_seg_paleta = segment(im)\n",
    "\n",
    "    # Estudiamos en que caso nos encontramos\n",
    "    img_cont, case, cent = define_case(img_seg_paleta, img_seg)\n",
    "    \n",
    "    # Estudiamos las marcas del fotograma\n",
    "    d = \"None\"\n",
    "    \n",
    "    if case < 3:\n",
    "        arrow = 2\n",
    "        acc = [0,0,0,0]\n",
    "        img_cont, acc_mark = study_marks(img_cont, img_seg, img_seg_paleta, acc_mark)\n",
    "    else:\n",
    "        img_cont, d, arrow, acc = study_arrow(img_cont, img_seg, case, arrow, acc)\n",
    "    \n",
    "    text = \"Flecha: \" + d \n",
    "    cv2.putText(img_cont, text, org_2, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    img_cont = eval_exit(img_cont, cent, arrow)\n",
    "    \n",
    "    # Muestro la imagen en una ventala OpenCV\n",
    "    cv2.imshow(\"Captura\", img_cont)\n",
    "    out.write(img_cont.astype('uint8'))\n",
    "\n",
    "    # Pausa si se pulsa P, stop si se pulsa Q\n",
    "    key = cv2.waitKey(35)\n",
    "    if key == ord('p'):\n",
    "        key = cv2.waitKey(-1) # Espero hasta que se pulse otra tecla\n",
    "\n",
    "# Cierro la ventana \n",
    "cv2.destroyAllWindows()\n",
    "capture.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "etiqueta_imagenes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
